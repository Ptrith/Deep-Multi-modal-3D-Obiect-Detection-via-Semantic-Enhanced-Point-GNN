#!/usr/bin/env python3
"""æµ‹è¯•å¤šæ¨¡æ€Point-GNNçš„æ‰€æœ‰æ–°æ¨¡å—"""

import sys
import numpy as np

def test_imports():
    """æµ‹è¯•æ‰€æœ‰æ¨¡å—å¯¼å…¥"""
    print("=" * 60)
    print("æµ‹è¯•1: æ¨¡å—å¯¼å…¥")
    print("=" * 60)
    
    try:
        from models.point_painting import PointPainter, SemanticSegmentationModel
        print("âœ… point_painting æ¨¡å—å¯¼å…¥æˆåŠŸ")
    except Exception as e:
        print(f"âŒ point_painting æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        from models.semantic_gnn import SemanticGraphNetAutoCenter, compute_semantic_similarity
        print("âœ… semantic_gnn æ¨¡å—å¯¼å…¥æˆåŠŸ")
    except Exception as e:
        print(f"âŒ semantic_gnn æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        from models.multimodal_models import MultiModalPointGNN
        print("âœ… multimodal_models æ¨¡å—å¯¼å…¥æˆåŠŸ")
    except Exception as e:
        print(f"âŒ multimodal_models æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        from models.enhanced_nms import nms_boxes_3d_semantic, adaptive_nms_threshold
        print("âœ… enhanced_nms æ¨¡å—å¯¼å…¥æˆåŠŸ")
    except Exception as e:
        print(f"âŒ enhanced_nms æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        from dataset.multimodal_kitti_dataset import MultiModalKittiDataset
        print("âœ… multimodal_kitti_dataset æ¨¡å—å¯¼å…¥æˆåŠŸ")
    except Exception as e:
        print(f"âŒ multimodal_kitti_dataset æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    print("\næ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸï¼\n")
    return True


def test_point_painting():
    """æµ‹è¯•PointPaintingåŠŸèƒ½"""
    print("=" * 60)
    print("æµ‹è¯•2: PointPaintingåŠŸèƒ½")
    print("=" * 60)
    
    try:
        from models.point_painting import PointPainter, SemanticSegmentationModel
        
        # åˆ›å»ºPointPainter
        painter = PointPainter(num_classes=19)
        print("âœ… PointPainteråˆ›å»ºæˆåŠŸ")
        
        # åˆ›å»ºè¯­ä¹‰åˆ†å‰²æ¨¡å‹ï¼ˆä½¿ç”¨dummyæ¨¡å¼ï¼‰
        seg_model = SemanticSegmentationModel(model_path=None, num_classes=19)
        print("âœ… SemanticSegmentationModelåˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•dummyåˆ†å‰²
        dummy_image = np.random.randint(0, 255, (375, 1242, 3), dtype=np.uint8)
        semantic_scores = seg_model._dummy_segmentation(dummy_image)
        print(f"âœ… Dummyåˆ†å‰²è¾“å‡ºå½¢çŠ¶: {semantic_scores.shape}")
        print(f"   è¯­ä¹‰æ¦‚ç‡å’Œ: {semantic_scores[100, 100, :].sum():.3f} (åº”è¯¥æ¥è¿‘1.0)")
        
        print("\nPointPaintingåŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼\n")
        return True
    except Exception as e:
        print(f"âŒ PointPaintingæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_semantic_gnn():
    """æµ‹è¯•è¯­ä¹‰æ„ŸçŸ¥GNN"""
    print("=" * 60)
    print("æµ‹è¯•3: è¯­ä¹‰æ„ŸçŸ¥GNN")
    print("=" * 60)
    
    try:
        import tensorflow as tf
        from models.semantic_gnn import compute_semantic_similarity
        
        # Disable eager execution for TF2.x compatibility
        try:
            tf.compat.v1.disable_eager_execution()
        except:
            pass
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        src_semantic = tf.constant([[0.8, 0.1, 0.1], [0.2, 0.7, 0.1]], dtype=tf.float32)
        dst_semantic = tf.constant([[0.7, 0.2, 0.1], [0.1, 0.1, 0.8]], dtype=tf.float32)
        
        # Use TF2.x compatible session
        try:
            Session = tf.compat.v1.Session
        except AttributeError:
            Session = tf.Session
        
        with Session() as sess:
            # æµ‹è¯•ä½™å¼¦ç›¸ä¼¼åº¦
            similarity = compute_semantic_similarity(src_semantic, dst_semantic, mode='cosine')
            sim_values = sess.run(similarity)
            print(f"âœ… ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—æˆåŠŸ: {sim_values.flatten()}")
            
            # æµ‹è¯•L2ç›¸ä¼¼åº¦
            similarity = compute_semantic_similarity(src_semantic, dst_semantic, mode='l2')
            sim_values = sess.run(similarity)
            print(f"âœ… L2ç›¸ä¼¼åº¦è®¡ç®—æˆåŠŸ: {sim_values.flatten()}")
        
        print("\nè¯­ä¹‰GNNåŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼\n")
        return True
    except Exception as e:
        print(f"âŒ è¯­ä¹‰GNNæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_enhanced_nms():
    """æµ‹è¯•å¢å¼ºçš„NMS"""
    print("=" * 60)
    print("æµ‹è¯•4: å¢å¼ºçš„NMS")
    print("=" * 60)
    
    try:
        from models.enhanced_nms import adaptive_nms_threshold, rescore_boxes_with_semantics
        
        # æµ‹è¯•è‡ªé€‚åº”é˜ˆå€¼
        box_labels = np.array([1, 1, 3, 3, 5])  # Car, Car, Pedestrian, Pedestrian, Cyclist
        thresholds = adaptive_nms_threshold(box_labels)
        print(f"âœ… è‡ªé€‚åº”é˜ˆå€¼: {thresholds}")
        print(f"   Caré˜ˆå€¼: {thresholds[0]}, Pedestriané˜ˆå€¼: {thresholds[2]}")
        
        # æµ‹è¯•è¯­ä¹‰é‡è¯„åˆ†
        detection_scores = np.array([0.8, 0.7, 0.6, 0.5, 0.9])
        semantic_scores = np.array([0.9, 0.8, 0.7, 0.6, 0.95])
        rescored = rescore_boxes_with_semantics(
            box_labels, None, detection_scores, semantic_scores, semantic_weight=0.3
        )
        print(f"âœ… è¯­ä¹‰é‡è¯„åˆ†:")
        print(f"   åŸå§‹åˆ†æ•°: {detection_scores}")
        print(f"   é‡è¯„åˆ†å: {rescored}")
        
        print("\nå¢å¼ºNMSåŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼\n")
        return True
    except Exception as e:
        print(f"âŒ å¢å¼ºNMSæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_config():
    """æµ‹è¯•é…ç½®åŠ è½½"""
    print("=" * 60)
    print("æµ‹è¯•5: é…ç½®æ–‡ä»¶")
    print("=" * 60)
    
    try:
        from util.config_util import load_config
        
        config_path = 'checkpoints/car_auto_T3_train/config'
        config = load_config(config_path)
        
        print(f"âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
        print(f"   æ¨¡å‹åç§°: {config['model_name']}")
        print(f"   ç±»åˆ«æ•°é‡: {config['num_classes']}")
        print(f"   æ ‡ç­¾æ–¹æ³•: {config['label_method']}")
        print(f"   è¾“å…¥ç‰¹å¾: {config['input_features']}")
        
        print("\né…ç½®æ–‡ä»¶æµ‹è¯•é€šè¿‡ï¼\n")
        return True
    except Exception as e:
        print(f"âŒ é…ç½®æ–‡ä»¶æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    print("\n" + "=" * 60)
    print("å¤šæ¨¡æ€Point-GNNåŠŸèƒ½æµ‹è¯•")
    print("=" * 60 + "\n")
    
    results = []
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    results.append(("æ¨¡å—å¯¼å…¥", test_imports()))
    results.append(("PointPainting", test_point_painting()))
    results.append(("è¯­ä¹‰GNN", test_semantic_gnn()))
    results.append(("å¢å¼ºNMS", test_enhanced_nms()))
    results.append(("é…ç½®æ–‡ä»¶", test_config()))
    
    # æ‰“å°æ€»ç»“
    print("=" * 60)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{name:20s}: {status}")
    
    print(f"\næ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¤šæ¨¡æ€Point-GNNå·²å‡†å¤‡å°±ç»ªã€‚")
        print("\nä¸‹ä¸€æ­¥:")
        print("  1. å‡†å¤‡KITTIæ•°æ®é›†")
        print("  2. è¿è¡Œæ¨ç†: python3 run_multimodal.py checkpoints/car_auto_T3_train/ --dataset_root_dir PATH")
        return 0
    else:
        print(f"\nâš ï¸  {total - passed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚")
        return 1


if __name__ == '__main__':
    sys.exit(main())

